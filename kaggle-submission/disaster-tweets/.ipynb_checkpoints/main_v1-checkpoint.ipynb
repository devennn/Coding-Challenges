{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import string\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('.').parent.absolute()\n",
    "\n",
    "full_train = os.path.join(path, 'raw-dataset', 'train.csv')\n",
    "train_df = pd.read_csv(full_train, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      0  1\n",
      "0     our deeds are the reason of this  may allah fo...  1\n",
      "1                 forest fire near la ronge sask canada  1\n",
      "2     all residents asked to shelter in place are be...  1\n",
      "3     13000 people receive  evacuation orders in cal...  1\n",
      "4     just got sent this photo from ruby  as smoke f...  1\n",
      "...                                                 ... ..\n",
      "7608  two giant cranes holding a bridge collapse int...  1\n",
      "7609  the out of control wild fires in california ev...  1\n",
      "7610               m194 0104 utc5km s of volcano hawaii  1\n",
      "7611  police investigating after an ebike collided w...  1\n",
      "7612  the latest more homes razed by northern califo...  1\n",
      "\n",
      "[7613 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tweet_text = train_df['text']\n",
    "clean_tweet = []\n",
    "hashtags_list = []\n",
    "for tweet in tweet_text:\n",
    "    # Remove links\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    # Remove newline\n",
    "    tweet = tweet.strip('\\n')\n",
    "    # Remove unicode\n",
    "    tweet = normalize('NFKD', tweet).encode('ascii','ignore')\n",
    "    # Remove username\n",
    "    tweet = re.sub('@[^\\s]+','',str(tweet))\n",
    "    clean_tweet.append(tweet)\n",
    "\n",
    "    # Store and remove hashtags\n",
    "    temp = re.findall('#[^\\s]+', tweet)\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    temp = [s.translate(table) for s in temp]\n",
    "    for hashtag in temp:\n",
    "        hashtag = re.sub(\"#\", \"\", hashtag)\n",
    "        hashtag = hashtag.lower()\n",
    "        if hashtag not in hashtags_list:\n",
    "            hashtags_list.append(hashtag)\n",
    "            \n",
    "temp = []\n",
    "for i in range(len(clean_tweet)):\n",
    "    tweet = clean_tweet[i]\n",
    "    tweet = re.sub('#[^\\s]+', '', tweet)\n",
    "    tweet = tweet.translate(table).lower()\n",
    "    tweet = tweet.replace('b', '', 1)\n",
    "    tweet = tweet.strip()\n",
    "    temp.append(tweet)\n",
    "processed_tweets = zip(temp, train_df['target'])\n",
    "processed_tweets = pd.DataFrame(processed_tweets)\n",
    "print(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3271 4342 0\n"
     ]
    }
   ],
   "source": [
    "# Checking number of tweets per target\n",
    "real, fake, unknown = 0, 0, 0\n",
    "real_tweet, fake_tweet = {}, {}\n",
    "for i in range(len(processed_tweets)):\n",
    "    temp = processed_tweets[1][i]\n",
    "    if temp == 1:\n",
    "        real += 1\n",
    "    elif temp == 0:\n",
    "        fake += 1\n",
    "    else:\n",
    "        unknown += 1\n",
    "print(real, fake, unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', lowercase=False)\n",
    "vect_tweets = count_vect.fit_transform(processed_tweets[0])\n",
    "vect_tweets = vect_tweets.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        vect_tweets, \n",
    "        processed_tweets[1],\n",
    "        train_size=0.80, \n",
    "        random_state=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "log_model = LogisticRegression(solver='lbfgs')\n",
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n",
      "0.7957977675640184\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = log_model.predict(X_test)\n",
    "print(len(y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "full_test = os.path.join(path, 'raw-dataset', 'test.csv')\n",
    "train_df = pd.read_csv(full_train, encoding='utf-8')\n",
    "with open('test_tweet.pkl', 'r') as f:\n",
    "    test_df = f.read()\n",
    "test_df = [test_df]\n",
    "test_df = count_vect.transform(test_df).toarray()\n",
    "new_prediction = log_model.predict(test_df)\n",
    "print(len(new_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
